# Community Notesにおける行列分解を用いた信頼度スコアリング

## 1. 概要

Community Notesでは、ノートの信頼度を評価するために行列分解（Matrix Factorization）を使用しています。この手法は、ノートと評価者の関係を低次元の潜在空間で表現することで、多様な視点からの評価を考慮したスコアリングを実現しています。

## 2. 入力データと行列の構築

### 2.1 評価データ
- 評価者がノートに対して付けた評価（helpful/not helpful）
  - Yes = 1.0
  - Somewhat = 0.5
  - No = 0.0
- 評価に付けられたタグ（"Sources not included", "Incorrect information"など）
- 評価者の地域情報
- 評価者の言語情報

### 2.2 データの前処理
- 評価者は最低10件の評価が必要
- ノートは最低5件の評価が必要
- 類似した投稿選択パターンを持つ評価者の評価を統合
- 低い信頼性スコアを持つ評価者の評価をフィルタリング

### 2.3 行列の構造
- ノートと評価者のマトリックス（note-rater matrix）
- 各セルは評価者がそのノートを有用と評価したかどうかを表す
- スパースな行列（ほとんどの評価者はほとんどのノートを評価していない）

## 3. 行列分解の手法

### 3.1 基本モデル

#### 行列の構造
[matrix_factorization/model.py](https://github.com/twitter/communitynotes/blob/main/sourcecode/scoring/matrix_factorization/model.py)より：

```python
class BiasedMatrixFactorization(torch.nn.Module):
    def __init__(self, n_users: int, n_notes: int, n_factors: int = 1):
        self.user_factors = torch.nn.Embedding(n_users, n_factors)
        self.note_factors = torch.nn.Embedding(n_notes, n_factors)
        self.user_intercepts = torch.nn.Embedding(n_users, 1)
        self.note_intercepts = torch.nn.Embedding(n_notes, 1)
```

入力行列：
- 行：評価者数（n_users）
- 列：ノート数（n_notes）
- 値：評価（helpful=1.0, somewhat=0.5, not helpful=0.0）

分解後の次元：
- 評価者因子（fᵤ）：1次元ベクトル
- ノート因子（fₙ）：1次元ベクトル
- インターセプト項：各評価者・ノートに1次元

#### 予測モデル
予測値の計算：
```
r̂_{un} = μ + i_u + i_n + f_u · f_n
```
- μ: グローバルインターセプト（全体の平均的な評価傾向）
- i_u: ユーザーインターセプト（評価者の一般的な評価傾向）
- i_n: ノートインターセプト（ノートの基本的な質）
- f_u · f_n: 1次元の内積（視点の一致度）

#### 1次元因子の意義
1. インターセプト項の強い正則化（λ = 0.15）により：
   - 多様な視点からの支持が必要
   - 極端なバイアスを抑制
   - コミュニティ全体のコンセンサスを重視

2. 因子の弱い正則化（λ = 0.03）により：
   - 視点の違いは許容
   - ただし1次元に制限することで極端な分極化を防止

この設計により：
- 「どちらの陣営にも支持されている」ノートは高いインターセプト値を獲得
- 「特定の視点からのみ支持されている」ノートは高い因子値を持つが、インターセプトは低く抑えられる
- 結果として、多様な視点から支持されるノートが「Helpful」と判定されやすい仕組みになっています

### 3.2 最適化
損失関数：
```
Σ(r_{un} - r̂_{un})² + λ_i(i_u² + i_n² + μ²) + λ_f(||f_u||² + ||f_n||²)
```
- λ_i = 0.15（インターセプト項の正則化）
- λ_f = 0.03（因子の正則化）
- インターセプト項の正則化を強くすることで、多様な視点からの評価を必要とする

### 3.3 実装の詳細
- PyTorchを使用した実装
- 勾配降下法による最適化
- 1次元の因子ベクトル（データセットの規模に応じて将来的に次元を増やす可能性）
- 1時間ごとに再学習を実行
- 損失が0.09を超えた場合は再学習を実行（局所解対策）

## 4. マルチモデルアプローチ

Community Notesでは、以下の複数のモデルを組み合わせて最終的な評価を行います。各モデルは優先順位を持ち、より信頼性の高いモデルの判断が優先されます：

### 4.1 モデルの優先順位と統合ロジック

1. Coreモデル（最優先）
   - 確立された地域（米国など）のノートを評価
   - 最も信頼性の高いベースラインモデル
   - CRHステータスを付与された場合、他のモデルによる上書きは不可
   - インターセプト閾値: 0.40以上でCRH判定

2. Expansionモデル（第2優先）
   - すべての地域のノートを評価
   - Coreモデルと同じパラメータを使用
   - Coreモデルでステータスが決定されなかった場合に適用
   - インターセプト閾値はCoreモデルと同様

3. Groupモデル（第3優先）
   - 非英語コミュニティ向けの特別なモデル
   - 地域やグループごとに別々の行列分解を実行
   - 以下の条件をすべて満たす場合のみCRHステータスを付与:
     - 現在NMRステータスのノートのみ対象
     - CoreまたはExpansionモデルのインターセプトが最小安全閾値（0.3）以上
     - グループモデルでCRH判定されている

4. トピックモデル（補助的）
   - 特定のトピックに特化したモデル
   - シードワードによるトピック分類
   - トピックごとの視点空間を学習
   - 主にCRHステータスの見直しに使用:
     - トピックモデルのインターセプトが0.24未満
     - または因子の絶対値が0.51を超える場合
     - かつトピック判定に十分な確信度がある場合
     - CRHステータスをNMRに戻す

### 4.2 モデル統合の特徴

1. 段階的な評価プロセス
   - より信頼性の高いモデルから順に評価
   - 各モデルは特定の条件下でのみステータスを変更可能
   - モデル間の矛盾を防ぐため、明確な優先順位付け

2. 安全性メカニズム
   - 最小インターセプト閾値による品質保証
   - 因子の大きさによる極端な意見の制御
   - トピックモデルによる追加チェック

3. 柔軟な拡張性
   - 新しい言語・地域へのグループモデルの追加が容易
   - トピック特化型モデルの独立した追加が可能
   - 各モデルの重みや閾値の調整が可能

## 5. スコアリング基準

### 5.1 タグの重み付け

評価タグの重みは、評価者とノートの因子ベクトル間の距離に基づいて計算されます：

```
a_{un} = 1 / (1 + (||f_u - f_n|| / f̃)^5)
```

ここで：
- f_u: 評価者の因子ベクトル（Z正規化済み）
- f_n: ノートの因子ベクトル（Z正規化済み）
- f̃: 評価者とノートの因子間の距離の40パーセンタイル値
- ||f_u - f_n||: 評価者とノートの因子ベクトル間のユークリッド距離

重み付けの特徴：
1. 距離が近いほど重みが1に近づく（同じ視点を持つ評価者の評価を重視）
2. 距離が遠いほど重みが0に近づく（異なる視点からの評価の影響を抑制）
3. 5乗を使用することで、距離に対して非線形な重み減衰を実現

タグの集計プロセス：
1. 各評価に対して重みa_{un}を計算
2. タグごとに重み付き合計を計算：
   - 生の合計: Σ tag_{un}
   - 調整済み合計: Σ (a_{un} × tag_{un})
   - 調整済み比率: (Σ (a_{un} × tag_{un})) / (Σ a_{un})
3. フィルタリング条件：
   - 調整済み合計が2.5を超える
   - 調整済み比率が上位5-10%（設定可能）に入る
   - この場合、ノートはNMR（Needs More Ratings）ステータスに戻される

この重み付けシステムにより：
- 同じ視点を持つ評価者からの評価を優先
- 極端に異なる視点からの評価の影響を抑制
- タグの濫用や意図的な誤用を防止
- コミュニティ内での合意形成を促進

### 5.2 評価者の信頼度判定

評価者の信頼度は、以下の3つの主要な基準に基づいて判定されます：

1. ノート作成者としての評価
   - CRH（Currently Rated Helpful）とCRNH（Currently Rated Not Helpful）の比率
   - CRNHには5倍のペナルティ重み付け
   - 計算式：`CRH率 - (CRNH率 × 5.0)`が最小閾値以上
   - ノートの平均インターセプトスコアが最小閾値以上

2. 評価者としての一致率
   - 評価が最終的なノートステータスと一致する割合
   - 計算式：`一致した評価数 / 総評価数`
   - 要件：一致率が最小閾値以上

3. ハラスメント・乱用評価のペナルティ
   - ハラスメントスコアが2.0以上のノートを「Helpful」と評価した場合
   - 基本ペナルティ：10ポイント
   - 実際のペナルティ：`10 × (ハラスメントスコア / 2.0)`
   - 調整済み一致率：`(一致評価数 - ハラスメントペナルティ合計) / 総評価数`
   - 要件：調整済み一致率が最小閾値以上

信頼度の低い評価者の判定：
- 上記3つの基準のいずれかを満たさない場合
- ノート作成実績がない場合は評価者基準のみで判定
- 信頼度が低いと判定された評価者の評価は、行列分解の学習データから除外

この仕組みにより：
- 質の高いノートを作成する評価者を重視
- コミュニティの合意形成に貢献する評価者を優遇
- 悪意のある評価や不適切な評価を効果的に排除
- 評価の質を継続的に監視・制御

### 5.3 "Helpful"ステータスの条件

### 5.3 ハラスメント・乱用タグの監視システム

ハラスメントや乱用に関する評価は、完全に自動化された以下のプロセスで処理されます：

1. タグのコンセンサス検出
   - ハラスメント/乱用タグの重み付き集計
   - スコアが2.0以上のノートを「ハラスメント/乱用の可能性が高い」と判定
   - 重み付けには標準的なa_{un}の計算式を使用

2. 評価者へのペナルティ
   - 基本ペナルティ：10ポイント
   - 実際のペナルティ = 10 × (ハラスメントスコア / 2.0)
   - 例：ハラスメントスコア4.0のノートを「Helpful」と評価した場合、20ポイントのペナルティ

3. 評価者スコアへの影響
   - 調整済み一致率 = (一致評価数 - ハラスメントペナルティ合計) / 総評価数
   - この調整済み一致率が最小閾値を下回ると、評価者の信頼度が低いと判定
   - 結果として、その評価者の評価は行列分解の学習データから除外

4. ノートステータスへの影響
   - ハラスメントスコアが高いノートは自動的にNMR（Needs More Ratings）に
   - "Incorrect"タグと同様のフィルタリングロジックを適用
   - 閾値：
     - タグ数の閾値（tagThreshold）
     - 評価者数の閾値（voteThreshold）
     - 重み付き合計の閾値（weightedTotalVotes）

このシステムの特徴：
- 完全自動化された判定プロセス
- 評価者の視点の近さに基づく重み付け
- ペナルティの段階的な適用
- コミュニティ全体の評価傾向との整合性確認

### 5.4 システム全体の特徴とパラメータ

1. データ規模と更新頻度
   - 最小要件：200ノート（minNumNotesForProdData）
   - タグ付けの閾値：2評価（minRatingsToGetTag）
   - ステータス確定の閾値：2タグ（minTagsNeededForStatus）
   - 更新頻度：1時間ごとの再学習
   - 安定化期間：30分（NmrDueToMinStableCrhTime）

2. 複数モデルの統合ロジック
   - コアモデル（Core）：基本的な信頼性評価、最優先の判定基準
   - 拡張モデル（Expansion）：より広い評価者層からの入力
   - グループモデル（Group）：地域・言語別の評価
   - トピックモデル（Topic）：分野別の専門性評価
   優先順位と処理：
   - コアモデルの判定が他のモデルより優先
   - トピックモデルで低信頼度判定された場合はNMRステータスに
   - 各モデルは独自の閾値と安定性基準を適用

3. 評価者の信頼度基準と重み付け
   - 基本評価基準：
     • 最小一致率（minRaterAgreeRatio）：評価の一貫性
     • 最小平均ノートスコア（minMeanNoteScore）：投稿の質
     • CRH/CRNH比率の最小差（minCRHVsCRNHRatio）：評価バランス
   - タグの重み付け計算：
     • a_{un} = 1 / (1 + (||fᵤ - fₙ|| / f̃)⁵)
     • fᵤ：評価者の因子ベクトル
     • fₙ：ノートの因子ベクトル
     • f̃：正規化係数
   - ペナルティ適用：
     • ハラスメントタグ付きノートへの誤評価は-10ポイント
     • ハラスメントスコア2.0以上で比例的にペナルティ増加

4. 安定性と品質管理
   - 最大CRH変動率：
     - 新規評価あり：80%（finalNotesWithNewRatingsMaxNewCrhChurn）
     - 既存評価のみ：25%（finalNotesWithNewRatingsMaxOldCrhChurn）
   - インターセプト正則化：極端な評価の抑制
   - 1次元因子による単純化：極端な意見の影響を制限

5. "Not Helpful"ステータスの条件
   - スコア < -0.05 - 0.8 * |noteFactorScore|
   - または信頼区間の上限が -0.04未満

6. ハラスメント・乱用タグの自動処理
   - 検出システム：
     • ハラスメントスコア（harassmentNoteIntercept）の自動計算
     • 閾値2.0以上で自動ペナルティ発動
     • 基本10ポイントのペナルティをスコアに応じて増加
   - 評価への影響：
     • 「Helpful」評価に対する自動ペナルティ適用
     • 評価者の信頼度スコアから直接減算
     • 複数回の誤評価で累積的なペナルティ
   - 完全自動化されたモニタリング：
     • 手動レビュープロセスなし
     • 1時間ごとの自動再評価
     • 30分の安定化期間で急激な変更を防止

## 6. 最新の改良（2024年2月）

拡張コンセンサストライアルでは、2段階の最適化プロセスを導入：

### 6.1 第1ラウンド
- 因子の正則化を減少
- インターセプトの正則化を増加
- ノートのインターセプトと因子の積に対する正則化を導入

### 6.2 第2ラウンド
- ユーザー因子に基づく評価の重み付け
- 異なる視点を持つユーザー間でのバランス調整
- アクティブユーザーの影響力の調整

この手法により、異なる視点を持つユーザー間でのコンセンサスをより効果的に検出できるようになっています。

## 7. スコアリングの安定性と不確実性

### 7.1 不確実性のモデリング
- 擬似評価（pseudo-ratings）による感度分析
  - 極端な評価を持つ擬似評価者を追加
  - パラメータの不確実性を定量化
  - 信頼区間の上限が-0.04未満の場合、"Not Helpful"と判定

### 7.2 スコアの安定性
- 2週間以上経過したノートのステータスを固定
- Core、Expansion、Groupモデルで決定されたステータスのみ固定
- 新しいノートは30分間の安定性確認期間
- 教師あり学習モデルによる信頼性の予測

### 7.3 再学習と品質管理
- 1時間ごとの定期的な再学習
- 損失が0.09を超えた場合の再学習実行
- 多様な視点からの評価を確保するための正則化
- ハラスメントや乱用に関する特別なモニタリング